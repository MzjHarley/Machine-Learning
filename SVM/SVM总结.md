SVM算法是一个很优秀的算法，在集成学习和神经网络之类的算法没有表现出优越性能前，SVM基本占据了分类模型的统治地位。目前则是在大数据时代的大样本背景下,SVM由于其在大样本时超级大的计算量，热度有所下降，但是仍然是一个常用的机器学习算法。

## SVM算法的主要优点

1) 解决高维特征的分类问题和回归问题很有效,在特征维度大于样本数时依然有很好的效果。  

2) 仅仅使用一部分支持向量来做超平面的决策，无需依赖全部数据。  

3) 有大量的核函数可以使用，从而可以很灵活的来解决各种非线性的分类回归问题。  

4) 样本量不是海量数据的时候，分类准确率高，泛化能力强。  

## SVM算法的主要缺点  

1) 如果特征维度远远大于样本数，则SVM表现一般。  

2) SVM在样本量非常大，核函数映射维度非常高时，计算量过大，不太适合使用。  

3) 非线性问题的核函数的选择没有通用标准，难以选择一个合适的核函数。
4)  SVM对缺失数据敏感。  
